{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMFZqTcKRhHQRlLH8G/pgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larasauser/2024_MLEES/blob/main/Project/project_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Machine learning Project - Sauser Lara**\n",
        "## *Filling gaps in NDVI images using CNN and Diffusion models*\n",
        "\n",
        "[Ajouter une image d'illustration]\n",
        "\n",
        "##Main steps :\n",
        "\n",
        "\n",
        "1.   Gather dataset\n",
        "2.   Split the dataset\n",
        "3.   Create the CNN alorithm\n",
        "4.   Create the Dissolution model\n",
        "5.   Evaluate them (RMSE ?)\n",
        "\n",
        "\n",
        "##Questions\n",
        "1.   Should I keep infos of date when cutting\n",
        "my images ?\n",
        "\n"
      ],
      "metadata": {
        "id": "dVyGSaYdWANM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading the data and separate them into smaller images (32x32 px)\n",
        "--- This should be done only once per image set because it takes time ---\n",
        "\n",
        "--- New image set should be used after this step ---\n",
        "\n"
      ],
      "metadata": {
        "id": "o_yvJQotYJyt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zuevR7yUU_ii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085874f0-e7a5-4226-f2f1-4a5fbd4f415c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Dataset stored on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "folder_path = '/content/drive/My Drive/NDVI_Images_Landsat8_10/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To have more images and to reduce computational cost, we decide to devide them into sub-images of 25x25 pixels."
      ],
      "metadata": {
        "id": "koSOQva9bP_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGWHDKLCbZJf",
        "outputId": "04eaef4f-5e41-4e74-ca11-2ce6bebcb2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#img=Image.open('/content/drive/My Drive/NDVI_Images_Landsat8_10/NDVI_Val_Herens_2023-11-08.tif')\n",
        "#img_width, img_height = img.size\n",
        "#print(img_width)\n",
        "#print(img_height)"
      ],
      "metadata": {
        "id": "DHkcWmytPA78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajouter de l'overlap ??"
      ],
      "metadata": {
        "id": "0IF2DiXDR41Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "def split_image(image_path, output_folder, sub_image_size=(32, 32)):\n",
        "    # Open image\n",
        "    img = Image.open(image_path)\n",
        "    img_width, img_height = img.size\n",
        "\n",
        "    # Image count\n",
        "    count = 0\n",
        "\n",
        "    # Division\n",
        "    for i in range(0, img_width, sub_image_size[0]):\n",
        "        for j in range(0, img_height, sub_image_size[1]):\n",
        "            # Cutting box\n",
        "            box = (i, j, i + sub_image_size[0], j + sub_image_size[1])\n",
        "            # Cutting\n",
        "            sub_image = img.crop(box)\n",
        "            # Verification (size)\n",
        "            if sub_image.size[0] > 0 and sub_image.size[1] > 0:\n",
        "                # Saving\n",
        "                sub_image.save(os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(image_path))[0]}_sub_image_{count}.tif\"))\n",
        "                count += 1\n",
        "    print(count)\n",
        "\n",
        "def process_all_images(input_folder, output_folder):\n",
        "    # List all tif file in input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.tif'):\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            print(f\"Image in treatment : {filename}\")\n",
        "            split_image(image_path, output_folder)\n"
      ],
      "metadata": {
        "id": "wLfxyfLybbBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split our images\n",
        "output_folder = '/content/drive/My Drive/NDVI_Images_Landsat8_10/split'\n",
        "process_all_images(folder_path, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE_VUrGCcKNo",
        "outputId": "4ba9d986-8cad-4136-b53a-39ca00479fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image in treatment : NDVI_Val_Herens_2013-04-18.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2013-11-12.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2013-12-30.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2013-11-28.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2014-03-20.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2014-06-08.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2014-10-30.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-02-19.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-04-24.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-04-08.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-08-30.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-05-10.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2015-12-20.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2016-10-03.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2016-04-10.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2016-12-06.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2017-03-28.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2017-01-23.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2017-04-29.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2018-06-19.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2017-04-13.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2018-10-09.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2018-10-25.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2019-01-29.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2019-02-14.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2019-08-25.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2020-01-16.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2019-12-31.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2020-03-04.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2020-05-07.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2021-01-18.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2021-03-23.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2021-04-08.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2021-08-14.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-01-21.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2021-10-17.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-03-10.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-03-26.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-04-27.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-07-16.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-08-01.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2022-09-18.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2023-06-17.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2023-08-20.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2023-10-07.tif\n",
            "600\n",
            "Image in treatment : NDVI_Val_Herens_2023-11-08.tif\n",
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images are now splitted. We now have 13'200 images to use for our model."
      ],
      "metadata": {
        "id": "hpNX1_Kpb_7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Convolution Neural Network (CNN)"
      ],
      "metadata": {
        "id": "UdAvLQAwcHnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n"
      ],
      "metadata": {
        "id": "oWadx2Mzb_tW",
        "outputId": "4cbec381-017b-4567-f8ed-179664f60dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.0 Data Augmentation ???"
      ],
      "metadata": {
        "id": "PYqQaNSp9clP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Split the dataset into train, test and validation set"
      ],
      "metadata": {
        "id": "lLYQhVw4hNOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil"
      ],
      "metadata": {
        "id": "DE0mzlezpO-Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source directory and the new directories for train, validation, and test sets\n",
        "source_dir = '/content/drive/My Drive/NDVI_Images_Landsat8_10/split'\n",
        "train_dir = '/content/drive/My Drive/NDVI_Images_Landsat8_10/train'\n",
        "val_dir = '/content/drive/My Drive/NDVI_Images_Landsat8_10/validation'\n",
        "test_dir = '/content/drive/My Drive/NDVI_Images_Landsat8_10/test'"
      ],
      "metadata": {
        "id": "hTIBgZLs7EaN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new directories if they don't exist\n",
        "for dir in [train_dir, val_dir, test_dir]:\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)"
      ],
      "metadata": {
        "id": "72SEH1Dj7Ia2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image files from the source directory\n",
        "all_images = [f for f in os.listdir(source_dir) if f.endswith(('.tif', '.tiff'))]"
      ],
      "metadata": {
        "id": "2GmxYQvz7MRy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the list of images\n",
        "random.shuffle(all_images)"
      ],
      "metadata": {
        "id": "qFXAsbIV7Rcx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of images for each set\n",
        "total_images = len(all_images)\n",
        "train_split = int(0.7 * total_images)\n",
        "val_split = int(0.2 * total_images)"
      ],
      "metadata": {
        "id": "I5kxeksp7Usz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the images into train, validation, and test sets\n",
        "train_images = all_images[:train_split]\n",
        "val_images = all_images[train_split:train_split+val_split]\n",
        "test_images = all_images[train_split+val_split:]"
      ],
      "metadata": {
        "id": "CcBz6vo-7a-7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to copy images to their respective directories\n",
        "def copy_images(image_list, destination):\n",
        "    for image in image_list:\n",
        "        src = os.path.join(source_dir, image)\n",
        "        dst = os.path.join(destination, image)\n",
        "        shutil.copy(src, dst)  # Use shutil.copy instead of shutil.move\n"
      ],
      "metadata": {
        "id": "Or1ccrih7fxc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the images to their respective directories\n",
        "copy_images(train_images, train_dir)\n",
        "copy_images(val_images, val_dir)\n",
        "copy_images(test_images, test_dir)"
      ],
      "metadata": {
        "id": "7_0BqPDE7lgP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total images: {total_images}\")\n",
        "print(f\"Training images: {len(train_images)}\")\n",
        "print(f\"Validation images: {len(val_images)}\")\n",
        "print(f\"Test images: {len(test_images)}\")"
      ],
      "metadata": {
        "id": "cb3XFR_q7ozT",
        "outputId": "ce538cc0-2127-488b-ff2d-465f315c29c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1928\n",
            "Training images: 1349\n",
            "Validation images: 385\n",
            "Test images: 194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Create fake holes in images for training"
      ],
      "metadata": {
        "id": "fZbCIxbB8-QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HnqQK5yl9Jsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOLMXYZq9MX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}